#!/usr/bin/env python
from __future__ import absolute_import

from sentry.runner import configure
configure()

import functools
import logging
from Queue import Queue
from threading import Thread

from sentry.models import Environment, Group, GroupEnvironment
from sentry.tagstore.v2.models import GroupTagValue

CHUNK_SIZE = 100
POOL_SIZE = 20

logger = logging.getLogger('backfill_group_env')


class SimpleThreadedWorkerPool(object):
    """\
    Manages a simple threaded worker pool. The pool will be started when the
    first job is submitted, and will run to process completion.
    """

    END = object()

    def __init__(self, size):
        assert size > 0, 'pool must have at laest one worker thread'

        self.__started = False
        self.__size = size
        self.__threads = []

    def __start(self):
        self.__tasks = tasks = Queue(maxsize=100)

        def consumer():
            while True:
                try:
                    task = tasks.get()
                    if task is self.END:
                        return
                    task()
                except Exception as e:
                    logger.exception(e)  # NOQA
                finally:
                    tasks.task_done()

        for _ in range(self.__size):
            t = Thread(target=consumer)
            t.setDaemon(True)
            t.start()
            self.__threads.append(t)

        self.__started = True

    def submit(self, task):
        """\
        Submit a task to the worker pool.
        """
        if not self.__started:
            self.__start()

        self.__tasks.put(task)

    def drain(self):
        if not self.__started:
            return

        for _ in range(self.__size):
            self.__tasks.put(self.END)

        for t in self.__threads:
            t.join()


def backfill_group_env():
    ENV_CACHE = dict(Environment.objects.values_list('id', 'name'))
    pool = SimpleThreadedWorkerPool(POOL_SIZE)

    last_pk = None
    qs = GroupEnvironment.objects.filter(first_seen__isnull=True).order_by('pk')
    remaining_count = qs.count()
    group_environments = list(qs[0:CHUNK_SIZE])

    logger.info('Backfilling %s GroupEnvironments' % (remaining_count,))  # NOQA

    while group_environments:
        last_pk = group_environments[-1].id

        project_by_group = dict(
            Group.objects.filter(
                id__in=[ge.group_id for ge in group_environments]
            ).values_list('id', 'project_id')
        )

        group_environments = [
            ge for ge in group_environments if ge.group_id in project_by_group and ge.environment_id in ENV_CACHE
        ]

        def _update_groupenv(group_env, project_id):
            env_name = ENV_CACHE.get(group_env.environment_id)
            if not env_name:
                return
            try:
                first_seen = GroupTagValue.objects.filter(
                    group_id=group_env.group_id,
                    project_id=project_id,
                    _key__key='environment',
                    _key__environment_id=group_env.environment_id,
                    _key__project_id=project_id,
                    _value__project_id=project_id,
                    _value__value=env_name,
                    first_seen__isnull=False,
                ).extra(
                    where=['tagstore_grouptagvalue.project_id = tagstore_tagkey.project_id', 'tagstore_grouptagvalue.project_id = tagstore_tagvalue.project_id']
                ).values_list('first_seen', flat=True).get()
            except GroupTagValue.DoesNotExist:
                return

            GroupEnvironment.objects.filter(
                id=group_env.id,
                first_seen__isnull=True,
            ).update(first_seen=first_seen)

        for ge in group_environments:
            pool.submit(functools.partial(_update_groupenv, ge, project_by_group[ge.group_id]))

        remaining_count = remaining_count - CHUNK_SIZE
        logger.info('%s GroupEnvironments remaining' % (remaining_count,))  # NOQA
        group_environments = list(qs.filter(pk__gt=last_pk)[0:CHUNK_SIZE])

    pool.drain()


if __name__ == '__main__':
    backfill_group_env()
